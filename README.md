# Machine-Learning Perceptron Learning Algorithm Tutorial

The basis of the Perceptron Learning Algorithm (PLA), and binary classification for that matter, revolves around the idea that there is no assumption on how past (the training data) is related to the future (the test data), then prediction is impossible.

The relationship in this case is that both past and future observations are both sampled independently from the same distribution.

The prediction boils down to making a weighted estimate, known as the discriminant D, where D = w0 + Î£ ğ‘¤ğ‘–xğ‘–ğ‘€ğ‘–=1.

Consider the feature vectors X = {x1, x2, x3, ...., xm} and Y = {y1, y2, y3, ...., ym} where m = the number of dimensions (or number of elements).


